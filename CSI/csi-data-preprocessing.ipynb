{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-13T20:00:10.954111Z",
     "start_time": "2024-11-13T20:00:10.943918Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the JSON files\n",
    "json_directory = \"./dataset/rumdect/Weibo/\"\n",
    "\n",
    "# Function to process individual JSON files\n",
    "def process_json_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        try:\n",
    "            data = json.load(file)\n",
    "            posts = []\n",
    "            users = []\n",
    "            for entry in data:  # Assuming JSON structure has 'value' as key\n",
    "                # Extract post data\n",
    "                post = {\n",
    "                    \"post_id\": entry.get(\"id\"),\n",
    "                    \"thread_id\": entry.get(\"mid\"),\n",
    "                    \"user_id\": entry.get(\"uid\"),\n",
    "                    \"text\": entry.get(\"text\"),\n",
    "                    \"reposts_count\": entry.get(\"reposts_count\"),\n",
    "                    \"likes_count\": entry.get(\"attitudes_count\"),\n",
    "                    \"comments_count\": entry.get(\"comments_count\"),\n",
    "                    \"parent_thread_id\": entry.get(\"parent\"),\n",
    "                    \"timestamp\": entry.get(\"t\")\n",
    "                }\n",
    "                posts.append(post)\n",
    "\n",
    "                # Extract user data\n",
    "                user = {\n",
    "                    \"user_id\": entry.get(\"uid\"),\n",
    "                    \"username\": entry.get(\"username\"),\n",
    "                    \"friends_count\": entry.get(\"friends_count\"),\n",
    "                    \"followers_count\": entry.get(\"followers_count\"),\n",
    "                    \"bi_followers_count\": entry.get(\"bi_followers_count\"),\n",
    "                    \"user_created_at\": entry.get(\"user_created_at\"),\n",
    "                    \"last_activity\": entry.get(\"t\")\n",
    "                }\n",
    "                users.append(user)\n",
    "            return posts, users\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON from file: {file_path}\")\n",
    "            return [], []\n",
    "\n",
    "# Process all JSON files in the directory\n",
    "def process_all_json_files(directory):\n",
    "    consolidated_posts = []\n",
    "    consolidated_users = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            posts, users = process_json_file(file_path)\n",
    "            # print(posts, users)\n",
    "            consolidated_posts.extend(posts)\n",
    "            consolidated_users.extend(users)\n",
    "    return consolidated_posts, consolidated_users\n",
    "\n",
    "# Process Labels\n",
    "def process_labels(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "        for line in file:\n",
    "            post_data = line.split(\"\\t\")\n",
    "            data.append({\n",
    "                \"post_id\": post_data[0].split(\":\")[-1],\n",
    "                \"label\": post_data[1].split(\":\")[-1],\n",
    "                \"children\": post_data[2].strip()\n",
    "            })\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extract posts and users data into DataFrame\n",
    "all_posts, all_users = process_all_json_files(json_directory)\n",
    "posts_df, users_df = pd.DataFrame(all_posts), pd.DataFrame(all_users)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T20:00:53.262155Z",
     "start_time": "2024-11-13T20:00:10.955267Z"
    }
   },
   "id": "33747df8a9b2b050",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "users_df = users_df.loc[users_df.groupby(\"user_id\")[\"last_activity\"].idxmax()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T20:01:33.353704Z",
     "start_time": "2024-11-13T20:00:53.263599Z"
    }
   },
   "id": "85d8d28f08ea2f6c",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "post_label_df = process_labels(\"./dataset/rumdect/Weibo.txt\")\n",
    "posts_merged_df = pd.merge(post_label_df, posts_df, on=\"post_id\", how=\"inner\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T20:01:35.318874Z",
     "start_time": "2024-11-13T20:01:33.355411Z"
    }
   },
   "id": "d15986b58e02b1e7",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "posts_df.to_csv(\"./dataset/weibo_posts_df.csv\", index=False)\n",
    "users_df.to_csv(\"./dataset/weibo_users_df.csv\", index=False)\n",
    "posts_merged_df.to_csv(\"./dataset/weibo_posts_merged_df.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T20:01:45.905706Z",
     "start_time": "2024-11-13T20:01:35.319728Z"
    }
   },
   "id": "73939ba2d0e01c03",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
